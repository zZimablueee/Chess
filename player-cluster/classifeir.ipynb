{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce604b71",
   "metadata": {},
   "source": [
    "根据得到的正负样本去训练分类器并分析所有选手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7e1e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install tensorflow\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "positive_df['label']=1\n",
    "negative_df['label']=0\n",
    "train_full=pd.concat([positive_df,negative_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85862520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'CenterControlScore', 'PieceActivityScore',\n",
       "       'KingSafetyScore', 'CastlingScore', 'KingTropismScore',\n",
       "       'KingDefendersScore', 'KingPawnShieldScore', 'KingZoneControlScore',\n",
       "       'KingDiagonalExposureScore', 'KingEscapeSquaresScore', 'CaptureRatio',\n",
       "       'PawnCenter', 'AveragePawnAdvanceDepth', 'CheckRatio', 'ForceRatio',\n",
       "       'PawnIsolateScore', 'PawnOverlapScore', 'PawnProtectScore',\n",
       "       'queen_1LifeRatio', 'rook_1LifeRatio', 'rook_2LifeRatio',\n",
       "       'bishop_1LifeRatio', 'bishop_2LifeRatio', 'knight_1LifeRatio',\n",
       "       'knight_2LifeRatio', 'pawn_1LifeRatio', 'pawn_2LifeRatio',\n",
       "       'pawn_3LifeRatio', 'pawn_4LifeRatio', 'pawn_5LifeRatio',\n",
       "       'pawn_6LifeRatio', 'pawn_7LifeRatio', 'pawn_8LifeRatio',\n",
       "       'queen_promo_1LifeRatio', 'queen_promo_2LifeRatio',\n",
       "       'queen_promo_3LifeRatio', 'queen_promo_4LifeRatio',\n",
       "       'queen_promo_5LifeRatio', 'queen_promo_6LifeRatio',\n",
       "       'queen_promo_7LifeRatio', 'queen_promo_8LifeRatio', 'Name', 'ELO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dynamic\n",
    "positive_df=pd.read_csv('Dynamic_1_final.csv')\n",
    "negative_df=pd.read_csv('Dynamic_0_final.csv')\n",
    "positive_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04a5cc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值填充完毕！再次检查 NaN: False\n",
      "划分验证集，找最佳epochs\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6167 - loss: 0.6586 - val_accuracy: 0.8140 - val_loss: 0.5886\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8099 - loss: 0.5324 - val_accuracy: 0.8430 - val_loss: 0.4569\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.4234 - val_accuracy: 0.8430 - val_loss: 0.3738\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3567 - val_accuracy: 0.8471 - val_loss: 0.3433\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.3215 - val_accuracy: 0.8430 - val_loss: 0.3407\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2859 - val_accuracy: 0.8430 - val_loss: 0.3406\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.2829 - val_accuracy: 0.8430 - val_loss: 0.3460\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2651 - val_accuracy: 0.8471 - val_loss: 0.3488\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.2620 - val_accuracy: 0.8595 - val_loss: 0.3446\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2479 - val_accuracy: 0.8595 - val_loss: 0.3492\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2381 - val_accuracy: 0.8595 - val_loss: 0.3526\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2239 - val_accuracy: 0.8636 - val_loss: 0.3547\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2077 - val_accuracy: 0.8471 - val_loss: 0.3655\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.1920 - val_accuracy: 0.8595 - val_loss: 0.3761\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1915 - val_accuracy: 0.8554 - val_loss: 0.3763\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.1816 - val_accuracy: 0.8430 - val_loss: 0.3785\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "最佳训练轮数约是: 6 轮\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#特征列\n",
    "ignore_cols = ['Unnamed: 0', 'Name', 'ELO', 'label']\n",
    "feature_cols = [col for col in train_full.columns if col not in ignore_cols]\n",
    "for col in feature_cols:\n",
    "    mean_val = train_full[col].mean()\n",
    "    train_full[col] = train_full[col].fillna(mean_val)\n",
    "print(\"缺失值填充完毕！再次检查 NaN:\", train_full[feature_cols].isnull().values.any())\n",
    "\n",
    "# 准备全量的 X 和 y\n",
    "X_full = train_full[feature_cols].values\n",
    "y_full = train_full['label'].values\n",
    "\n",
    "print(\"划分验证集，找最佳epochs\")\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_full, y_full, test_size=0.2, random_state=42)\n",
    "\n",
    "#标准化\n",
    "scaler_split = StandardScaler()\n",
    "X_train_split_scaled = scaler_split.fit_transform(X_train_split)\n",
    "X_val_split_scaled = scaler_split.transform(X_val_split)\n",
    "\n",
    "#模型构建函数\n",
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model_scout = build_model(X_train_split.shape[1])\n",
    "\n",
    "#Early Stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#找拿到 best_epoch\n",
    "history = model_scout.fit(\n",
    "    X_train_split_scaled, y_train_split,\n",
    "    validation_data=(X_val_split_scaled, y_val_split),\n",
    "    epochs=100, #较大的上限，反正早停会拦住\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 获取最佳轮数\n",
    "# 如果早停触发了，best_epoch 就是停止时的轮数减去 patience；如果没有触发，就是设置的 epochs\n",
    "# 实际上 EarlyStopping 比较智能，我们可以直接看它实际跑了多少轮\n",
    "optimal_epochs = len(history.history['loss']) \n",
    "if early_stop.stopped_epoch > 0:\n",
    "    # stopped_epoch 是索引（从0开始），且包含了耐心值的轮数\n",
    "    # 为了保险，我们取最佳权重的那个 epoch 数量\n",
    "    # (patience 期间 loss 没降，所以最佳 epoch 是 stopped_epoch - patience + 1)\n",
    "    optimal_epochs = max(1, early_stop.stopped_epoch - 10 + 1)\n",
    "\n",
    "print(f\"\\n最佳训练轮数约是: {optimal_epochs} 轮\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd75a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征列\n",
    "ignore_cols = ['Unnamed: 0', 'Name', 'ELO', 'label']\n",
    "feature_cols = [col for col in train_full.columns if col not in ignore_cols]\n",
    "# 准备全量的 X 和 y\n",
    "X_full = train_full[feature_cols].values\n",
    "y_full = train_full['label'].values\n",
    "\n",
    "print(\"划分验证集，找最佳epochs\")\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_full, y_full, test_size=0.2, random_state=42)\n",
    "\n",
    "#标准化\n",
    "scaler_split = StandardScaler()\n",
    "X_train_split_scaled = scaler_split.fit_transform(X_train_split)\n",
    "X_val_split_scaled = scaler_split.transform(X_val_split)\n",
    "\n",
    "#模型构建函数\n",
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model_scout = build_model(X_train_split.shape[1])\n",
    "\n",
    "#Early Stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#找拿到 best_epoch\n",
    "history = model_scout.fit(\n",
    "    X_train_split_scaled, y_train_split,\n",
    "    validation_data=(X_val_split_scaled, y_val_split),\n",
    "    epochs=100, #较大的上限，反正早停会拦住\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 获取最佳轮数\n",
    "# 如果早停触发了，best_epoch 就是停止时的轮数减去 patience；如果没有触发，就是设置的 epochs\n",
    "# 实际上 EarlyStopping 比较智能，我们可以直接看它实际跑了多少轮\n",
    "optimal_epochs = len(history.history['loss']) \n",
    "if early_stop.stopped_epoch > 0:\n",
    "    # stopped_epoch 是索引（从0开始），且包含了耐心值的轮数\n",
    "    # 为了保险，我们取最佳权重的那个 epoch 数量\n",
    "    # (patience 期间 loss 没降，所以最佳 epoch 是 stopped_epoch - patience + 1)\n",
    "    optimal_epochs = max(1, early_stop.stopped_epoch - 10 + 1)\n",
    "\n",
    "print(f\"\\n最佳训练轮数约是: {optimal_epochs} 轮\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 第二阶段：全量实战 (Retrain on Full Data)\n",
    "# ==========================================\n",
    "print(f\"用全量数据训练 {optimal_epochs} 轮 ---\")\n",
    "\n",
    "# 1. 全量标准化 (这次根据所有数据拟合 scaler)\n",
    "scaler_final = StandardScaler()\n",
    "X_full_scaled = scaler_final.fit_transform(X_full)\n",
    "\n",
    "# 2. 重新构建一个干净的模型\n",
    "model_final = build_model(X_full.shape[1])\n",
    "\n",
    "# 3. 全量训练 (不再需要 validation_data，也不需要 early_stop，直接跑最佳轮数)\n",
    "model_final.fit(\n",
    "    X_full_scaled, y_full,\n",
    "    epochs=optimal_epochs, \n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 第三阶段：预测 Test Data\n",
    "# ==========================================\n",
    "print(\"\\n--- 第三阶段：预测 Test Data ---\")\n",
    "\n",
    "# 1. 准备测试数据\n",
    "X_test = test_df[feature_cols].values\n",
    "\n",
    "# 2. 使用全量的 scaler 进行转换 (必须用 scaler_final)\n",
    "X_test_scaled = scaler_final.transform(X_test)\n",
    "\n",
    "# 3. 预测概率\n",
    "probs = model_final.predict(X_test_scaled).flatten()\n",
    "\n",
    "# 4. 写入结果\n",
    "new_col_name = 'Style_Prob_NN'\n",
    "test_df[new_col_name] = probs\n",
    "\n",
    "print(f\"预测完成！结果已保存至列: {new_col_name}\")\n",
    "print(test_df[['Name', new_col_name]].head())\n",
    "\n",
    "# test_df.to_csv(\"final_result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
